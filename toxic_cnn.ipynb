{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "%load_ext autotime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Nueral Network with Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('train.csv',engine='python')\n",
    "test = pd.read_csv('test.csv',engine='python')\n",
    "# after processing some of the texts are emply\n",
    "train['comment_text'] = train['comment_text'].fillna('')\n",
    "test['comment_text'] = test['comment_text'].fillna('')\n",
    "sub = pd.read_csv('sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.text import Tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Limit to top 300,000 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_text = list(train['comment_text'].values) + list(test['comment_text'].values)\n",
    "max_features = 300000\n",
    "tk = Tokenizer(lower = True, filters='', num_words=max_features)\n",
    "tk.fit_on_texts(full_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add fast_text and Glove word embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_path1 = \"crawl-300d-2M.vec\"\n",
    "embedding_path2 = \"glove.840B.300d.txt\"\n",
    "embed_size = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_coefs(word,*arr):\n",
    "    return word, np.asarray(arr, dtype='float32')\n",
    "\n",
    "def build_matrix(embedding_path, tokenizer):\n",
    "    embedding_index = dict(get_coefs(*o.strip().split(\" \")) for o in open(embedding_path))\n",
    "\n",
    "    word_index = tk.word_index\n",
    "    nb_words = min(max_features, len(word_index))\n",
    "    embedding_matrix = np.zeros((nb_words + 1, embed_size))\n",
    "    for word, i in word_index.items():\n",
    "        if i >= max_features:\n",
    "            continue\n",
    "        embedding_vector = embedding_index.get(word)\n",
    "        if embedding_vector is not None:\n",
    "            embedding_matrix[i] = embedding_vector\n",
    "    return embedding_matrix\n",
    "\n",
    "# combining embeddings from this kernel: https://www.kaggle.com/tanreinama/simple-lstm-using-identity-parameters-solution\n",
    "embedding_matrix = np.concatenate([build_matrix(embedding_path1, tk), build_matrix(embedding_path2, tk)], axis=-1)\n",
    "\n",
    "y = np.where(train['target'] >= 0.5, True, False) * 1\n",
    "\n",
    "identity_columns = ['male', 'female', 'homosexual_gay_or_lesbian', 'christian', 'jewish', \n",
    "                    'muslim', 'black', 'white', 'psychiatric_or_mental_illness']\n",
    "for col in identity_columns + ['target']:\n",
    "    train[col] = np.where(train[col] >= 0.5, True, False)\n",
    "\n",
    "n_fold = 5\n",
    "\n",
    "folds = StratifiedKFold(n_splits=n_fold, shuffle=True, random_state=11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from keras import Input\n",
    "from keras.layers import Activation, Dense, Embedding, SpatialDropout1D, Flatten, Dropout, concatenate\n",
    "from keras import initializers, regularizers, constraints, optimizers, layers, Model\n",
    "from keras.engine.topology import Layer\n",
    "from keras.layers.convolutional import Conv1D, MaxPooling1D\n",
    "from keras.optimizers import Adam\n",
    "from sklearn import metrics\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import keras.layers as L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 6.86 ms\n"
     ]
    }
   ],
   "source": [
    "SUBGROUP_AUC = 'subgroup_auc'\n",
    "BPSN_AUC = 'bpsn_auc'  # stands for background positive, subgroup negative\n",
    "BNSP_AUC = 'bnsp_auc'  # stands for background negative, subgroup positive\n",
    "\n",
    "TOXICITY_COLUMN = 'target'\n",
    "\n",
    "def compute_auc(y_true, y_pred):\n",
    "    try:\n",
    "        return metrics.roc_auc_score(y_true, y_pred)\n",
    "    except ValueError:\n",
    "        return np.nan\n",
    "\n",
    "def compute_subgroup_auc(df, subgroup, label, model_name):\n",
    "    subgroup_examples = df[df[subgroup]]\n",
    "    return compute_auc(subgroup_examples[label], subgroup_examples[model_name])\n",
    "\n",
    "def compute_bpsn_auc(df, subgroup, label, model_name):\n",
    "    \"\"\"Computes the AUC of the within-subgroup negative examples and the background positive examples.\"\"\"\n",
    "    subgroup_negative_examples = df[df[subgroup] & ~df[label]]\n",
    "    non_subgroup_positive_examples = df[~df[subgroup] & df[label]]\n",
    "    examples = subgroup_negative_examples.append(non_subgroup_positive_examples)\n",
    "    return compute_auc(examples[label], examples[model_name])\n",
    "\n",
    "def compute_bnsp_auc(df, subgroup, label, model_name):\n",
    "    \"\"\"Computes the AUC of the within-subgroup positive examples and the background negative examples.\"\"\"\n",
    "    subgroup_positive_examples = df[df[subgroup] & df[label]]\n",
    "    non_subgroup_negative_examples = df[~df[subgroup] & ~df[label]]\n",
    "    examples = subgroup_positive_examples.append(non_subgroup_negative_examples)\n",
    "    return compute_auc(examples[label], examples[model_name])\n",
    "\n",
    "def compute_bias_metrics_for_model(dataset,\n",
    "                                   subgroups,\n",
    "                                   model,\n",
    "                                   label_col,\n",
    "                                   include_asegs=False):\n",
    "    \"\"\"Computes per-subgroup metrics for all subgroups and one model.\"\"\"\n",
    "    records = []\n",
    "    for subgroup in subgroups:\n",
    "        record = {\n",
    "            'subgroup': subgroup,\n",
    "            'subgroup_size': len(dataset[dataset[subgroup]])\n",
    "        }\n",
    "        record[SUBGROUP_AUC] = compute_subgroup_auc(dataset, subgroup, label_col, model)\n",
    "        record[BPSN_AUC] = compute_bpsn_auc(dataset, subgroup, label_col, model)\n",
    "        record[BNSP_AUC] = compute_bnsp_auc(dataset, subgroup, label_col, model)\n",
    "        records.append(record)\n",
    "    return pd.DataFrame(records).sort_values('subgroup_auc', ascending=True)\n",
    "\n",
    "def calculate_overall_auc(df, model_name):\n",
    "    true_labels = df[TOXICITY_COLUMN]\n",
    "    predicted_labels = df[model_name]\n",
    "    return metrics.roc_auc_score(true_labels, predicted_labels)\n",
    "\n",
    "def power_mean(series, p):\n",
    "    total = sum(np.power(series, p))\n",
    "    return np.power(total / len(series), 1 / p)\n",
    "\n",
    "def get_final_metric(bias_df, overall_auc, POWER=-5, OVERALL_MODEL_WEIGHT=0.25):\n",
    "    bias_score = np.average([\n",
    "        power_mean(bias_df[SUBGROUP_AUC], POWER),\n",
    "        power_mean(bias_df[BPSN_AUC], POWER),\n",
    "        power_mean(bias_df[BNSP_AUC], POWER)\n",
    "    ])\n",
    "    return (OVERALL_MODEL_WEIGHT * overall_auc) + ((1 - OVERALL_MODEL_WEIGHT) * bias_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0 started at Tue May 28 12:18:10 2019\n",
      "Train on 1443899 samples, validate on 360975 samples\n",
      "Epoch 1/3\n",
      " - 1808s - loss: 0.1658 - acc: 0.9412 - val_loss: 0.1566 - val_acc: 0.9439\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.15664, saving model to checkpoint/best_model_fold_0.hdf5\n",
      "Epoch 2/3\n",
      " - 1807s - loss: 0.1549 - acc: 0.9446 - val_loss: 0.1540 - val_acc: 0.9447\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.15664 to 0.15399, saving model to checkpoint/best_model_fold_0.hdf5\n",
      "Epoch 3/3\n",
      " - 1807s - loss: 0.1511 - acc: 0.9456 - val_loss: 0.1541 - val_acc: 0.9446\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.15399\n",
      "97320/97320 [==============================] - 48s 496us/step\n",
      "Fold 1 started at Tue May 28 13:52:56 2019\n",
      "Train on 1443899 samples, validate on 360975 samples\n",
      "Epoch 1/3\n",
      " - 1805s - loss: 0.1659 - acc: 0.9413 - val_loss: 0.1555 - val_acc: 0.9442\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.15550, saving model to checkpoint/best_model_fold_1.hdf5\n",
      "Epoch 2/3\n",
      " - 1804s - loss: 0.1552 - acc: 0.9444 - val_loss: 0.1533 - val_acc: 0.9446\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.15550 to 0.15331, saving model to checkpoint/best_model_fold_1.hdf5\n",
      "Epoch 3/3\n",
      " - 1804s - loss: 0.1512 - acc: 0.9456 - val_loss: 0.1525 - val_acc: 0.9452\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.15331 to 0.15246, saving model to checkpoint/best_model_fold_1.hdf5\n",
      "97320/97320 [==============================] - 48s 496us/step\n",
      "Fold 2 started at Tue May 28 15:27:31 2019\n",
      "Train on 1443899 samples, validate on 360975 samples\n",
      "Epoch 1/3\n",
      " - 1806s - loss: 0.1656 - acc: 0.9413 - val_loss: 0.1551 - val_acc: 0.9445\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.15512, saving model to checkpoint/best_model_fold_2.hdf5\n",
      "Epoch 2/3\n",
      " - 1804s - loss: 0.1546 - acc: 0.9445 - val_loss: 0.1539 - val_acc: 0.9450\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.15512 to 0.15391, saving model to checkpoint/best_model_fold_2.hdf5\n",
      "Epoch 3/3\n",
      " - 1802s - loss: 0.1507 - acc: 0.9456 - val_loss: 0.1530 - val_acc: 0.9452\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.15391 to 0.15301, saving model to checkpoint/best_model_fold_2.hdf5\n",
      "97320/97320 [==============================] - 48s 496us/step\n",
      "Fold 3 started at Tue May 28 17:02:16 2019\n",
      "Train on 1443899 samples, validate on 360975 samples\n",
      "Epoch 1/3\n",
      " - 1800s - loss: 0.1653 - acc: 0.9417 - val_loss: 0.1556 - val_acc: 0.9440\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.15560, saving model to checkpoint/best_model_fold_3.hdf5\n",
      "Epoch 2/3\n",
      " - 1799s - loss: 0.1548 - acc: 0.9447 - val_loss: 0.1523 - val_acc: 0.9453\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.15560 to 0.15233, saving model to checkpoint/best_model_fold_3.hdf5\n",
      "Epoch 3/3\n",
      " - 1799s - loss: 0.1511 - acc: 0.9456 - val_loss: 0.1522 - val_acc: 0.9453\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.15233 to 0.15223, saving model to checkpoint/best_model_fold_3.hdf5\n",
      "97320/97320 [==============================] - 48s 496us/step\n",
      "Fold 4 started at Tue May 28 18:36:38 2019\n",
      "Train on 1443900 samples, validate on 360974 samples\n",
      "Epoch 1/3\n",
      " - 1804s - loss: 0.1652 - acc: 0.9415 - val_loss: 0.1550 - val_acc: 0.9445\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.15499, saving model to checkpoint/best_model_fold_4.hdf5\n",
      "Epoch 2/3\n",
      " - 1803s - loss: 0.1548 - acc: 0.9446 - val_loss: 0.1522 - val_acc: 0.9452\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.15499 to 0.15219, saving model to checkpoint/best_model_fold_4.hdf5\n",
      "Epoch 3/3\n",
      " - 1803s - loss: 0.1512 - acc: 0.9455 - val_loss: 0.1513 - val_acc: 0.9453\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.15219 to 0.15127, saving model to checkpoint/best_model_fold_4.hdf5\n",
      "97320/97320 [==============================] - 48s 496us/step\n",
      "CV mean score: 0.8767, std: 0.0022.\n",
      "time: 7h 53min 5s\n"
     ]
    }
   ],
   "source": [
    "# adding attention from this kernel: https://www.kaggle.com/christofhenkel/keras-baseline-lstm-attention-5-fold\n",
    "class Attention(Layer):\n",
    "    def __init__(self, step_dim,\n",
    "                 W_regularizer=None, b_regularizer=None,\n",
    "                 W_constraint=None, b_constraint=None,\n",
    "                 bias=True, **kwargs):\n",
    "        self.supports_masking = True\n",
    "        self.init = initializers.get('glorot_uniform')\n",
    "\n",
    "        self.W_regularizer = regularizers.get(W_regularizer)\n",
    "        self.b_regularizer = regularizers.get(b_regularizer)\n",
    "\n",
    "        self.W_constraint = constraints.get(W_constraint)\n",
    "        self.b_constraint = constraints.get(b_constraint)\n",
    "\n",
    "        self.bias = bias\n",
    "        self.step_dim = step_dim\n",
    "        self.features_dim = 0\n",
    "        super(Attention, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        assert len(input_shape) == 3\n",
    "\n",
    "        self.W = self.add_weight((input_shape[-1],),\n",
    "                                 initializer=self.init,\n",
    "                                 name='{}_W'.format(self.name),\n",
    "                                 regularizer=self.W_regularizer,\n",
    "                                 constraint=self.W_constraint)\n",
    "        self.features_dim = input_shape[-1]\n",
    "\n",
    "        if self.bias:\n",
    "            self.b = self.add_weight((input_shape[1],),\n",
    "                                     initializer='zero',\n",
    "                                     name='{}_b'.format(self.name),\n",
    "                                     regularizer=self.b_regularizer,\n",
    "                                     constraint=self.b_constraint)\n",
    "        else:\n",
    "            self.b = None\n",
    "\n",
    "        self.built = True\n",
    "\n",
    "    def compute_mask(self, input, input_mask=None):\n",
    "        return None\n",
    "\n",
    "    def call(self, x, mask=None):\n",
    "        features_dim = self.features_dim\n",
    "        step_dim = self.step_dim\n",
    "\n",
    "        eij = K.reshape(K.dot(K.reshape(x, (-1, features_dim)),\n",
    "                        K.reshape(self.W, (features_dim, 1))), (-1, step_dim))\n",
    "\n",
    "        if self.bias:\n",
    "            eij += self.b\n",
    "\n",
    "        eij = K.tanh(eij)\n",
    "\n",
    "        a = K.exp(eij)\n",
    "\n",
    "        if mask is not None:\n",
    "            a *= K.cast(mask, K.floatx())\n",
    "\n",
    "        a /= K.cast(K.sum(a, axis=1, keepdims=True) + K.epsilon(), K.floatx())\n",
    "\n",
    "        a = K.expand_dims(a)\n",
    "        weighted_input = x * a\n",
    "        return K.sum(weighted_input, axis=1)\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return input_shape[0],  self.features_dim\n",
    "    \n",
    "\n",
    "def build_model(X_train, y_train, X_valid, y_valid, max_len, max_features, embed_size, \n",
    "                embedding_matrix, lr=0.0, lr_d=0.0, spatial_dr=0.0,\n",
    "                dense_units=128, conv_size=128, dr=0.2, patience=3, fold_id=1):\n",
    "    file_path = \"checkpoint/best_model_fold_{}.hdf5\".format(fold_id)\n",
    "    check_point = ModelCheckpoint(file_path, monitor=\"val_loss\", verbose=1,save_best_only=True, mode=\"min\")\n",
    "    early_stop = EarlyStopping(monitor=\"val_loss\", mode=\"min\", patience=patience)\n",
    "    \n",
    "    inp = Input(shape = (max_len,))\n",
    "    x = Embedding(max_features + 1, embed_size * 2, weights=[embedding_matrix], trainable=False)(inp)\n",
    "    x1 = SpatialDropout1D(spatial_dr)(x)\n",
    "    att = Attention(max_len)(x1)\n",
    "    # from benchmark kernel\n",
    "    x = Conv1D(conv_size, 2, activation='relu', padding='same')(x1)\n",
    "    x = MaxPooling1D(5, padding='same')(x)\n",
    "    x = Conv1D(conv_size, 3, activation='relu', padding='same')(x)\n",
    "    x = MaxPooling1D(5, padding='same')(x)\n",
    "    x = Flatten()(x)\n",
    "    x = concatenate([x, att])\n",
    "    \n",
    "    x = Dropout(dr)(Dense(dense_units, activation='relu') (x))\n",
    "    x = Dense(1, activation=\"sigmoid\")(x)\n",
    "    \n",
    "    model = Model(inputs=inp, outputs=x)\n",
    "    model.compile(loss=\"binary_crossentropy\", optimizer=Adam(lr=lr, decay=lr_d), metrics=[\"accuracy\"])\n",
    "    model.fit(X_train, y_train, batch_size=128, epochs=3, validation_data=(X_valid, y_valid), \n",
    "                        verbose=2, callbacks=[early_stop, check_point])\n",
    "    return model\n",
    "\n",
    "# Training fuction\n",
    "\n",
    "def train_model(X, X_test, y, tokenizer, max_len):\n",
    "    \n",
    "    oof = np.zeros((len(X), 1))\n",
    "    prediction = np.zeros((len(X_test), 1))\n",
    "    test_tokenized = tokenizer.t\n",
    "    scores = []exts_to_sequences(test['comment_text'])\n",
    "    X_test = pad_sequences(test_tokenized, maxlen = max_len)\n",
    "    for fold_n, (train_index, valid_index) in enumerate(folds.split(X, y)):\n",
    "        print('Fold', fold_n, 'started at', time.ctime())\n",
    "        X_train, X_valid = X.iloc[train_index], X.iloc[valid_index]\n",
    "        y_train, y_valid = y.iloc[train_index], y.iloc[valid_index]\n",
    "        valid_df = X_valid.copy()    \n",
    "\n",
    "        train_tokenized = tokenizer.texts_to_sequences(X_train['comment_text'])\n",
    "        valid_tokenized = tokenizer.texts_to_sequences(X_valid['comment_text'])\n",
    "\n",
    "        X_train = pad_sequences(train_tokenized, maxlen = max_len)\n",
    "        X_valid = pad_sequences(valid_tokenized, maxlen = max_len)\n",
    "        \n",
    "        model = build_model(X_train, y_train, X_valid, y_valid, max_len, max_features, embed_size, embedding_matrix,\n",
    "                            lr = 1e-3, lr_d = 0, spatial_dr = 0.1, dense_units=128, conv_size=128, \n",
    "                            dr=0.1, patience=3, fold_id=fold_n)\n",
    "        \n",
    "        pred_valid = model.predict(X_valid)\n",
    "        oof[valid_index] = pred_valid\n",
    "        valid_df[oof_name] = pred_valid\n",
    "        \n",
    "        bias_metrics_df = compute_bias_metrics_for_model(valid_df, identity_columns, oof_name, 'target')\n",
    "        scores.append(get_final_metric(bias_metrics_df, calculate_overall_auc(valid_df, oof_name)))\n",
    "        \n",
    "        prediction += model.predict(X_test, batch_size = 1024, verbose = 1)\n",
    "    \n",
    "    prediction /= n_fold\n",
    "    \n",
    "    # print('CV mean score: {0:.4f}, std: {1:.4f}.'.format(np.mean(scores), np.std(scores)))\n",
    "    return oof, prediction, scores\n",
    "\n",
    "#Train and predict\n",
    "\n",
    "oof_name = 'predicted_target'\n",
    "max_len = 250\n",
    "oof, prediction, scores = train_model(X=train, X_test=test, y=train['target'], tokenizer=tk, max_len=max_len)\n",
    "print('CV mean score: {0:.4f}, std: {1:.4f}.'.format(np.mean(scores), np.std(scores)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using kaggle metric score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.8780763861509111,\n",
       " 0.8782600987367287,\n",
       " 0.8763849165201163,\n",
       " 0.8725172735339072,\n",
       " 0.8784967378807498]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 63 ms\n"
     ]
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 2.13 ms\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score, confusion_matrix, accuracy_score, roc_auc_score, precision_score, recall_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 395 ms\n"
     ]
    }
   ],
   "source": [
    "x = train.copy()\n",
    "x[\"pred_maybe\"] = oof"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 701 ms\n"
     ]
    }
   ],
   "source": [
    "x.loc[x.pred_maybe > 0.5, \"target_maybe\"] = True\n",
    "x.target_maybe.fillna(False, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5740202068882424"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 316 ms\n"
     ]
    }
   ],
   "source": [
    "f1_score(x[\"target\"],x[\"target_maybe\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 672 ms\n"
     ]
    }
   ],
   "source": [
    "cm = confusion_matrix(x[\"target\"],x[\"target_maybe\"])\n",
    "ax= plt.subplot()\n",
    "sns.heatmap(cm, annot=True, ax = ax, fmt='g'); #annot=True to annotate cells\n",
    "\n",
    "# labels, title and ticks\n",
    "ax.set_xlabel('Predicted labels')\n",
    "ax.set_ylabel('True labels') \n",
    "ax.set_title('Confusion Matrix') \n",
    "ax.xaxis.set_ticklabels(['non-toxic', 'toxic'])\n",
    "ax.yaxis.set_ticklabels(['non-toxic', 'toxic'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9451507418246371"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 78.5 ms\n"
     ]
    }
   ],
   "source": [
    "accuracy_score(x[\"target\"],x[\"target_maybe\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7574209079966387"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 308 ms\n"
     ]
    }
   ],
   "source": [
    "precision_score(x[\"target\"],x[\"target_maybe\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4621225768010309"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 309 ms\n"
     ]
    }
   ],
   "source": [
    "recall_score(x[\"target\"],x[\"target_maybe\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.724629043468144"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 264 ms\n"
     ]
    }
   ],
   "source": [
    "roc_auc_score(x[\"target\"],x[\"target_maybe\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
